{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "tFuep2p2lW1d"
      },
      "outputs": [],
      "source": [
        "#imports\n",
        "import numpy as np\n",
        "from skimage import io\n",
        "from skimage.transform import resize\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "import matplotlib.patches as patches\n",
        "import os\n",
        "\n",
        "import torch\n",
        "import torchvision\n",
        "from torchvision import ops\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "#imports\n",
        "from tqdm import tqdm\n",
        "import pickle"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#To use in Colab\n",
        "!git clone https://github.com/gabriellecaillaud/APS360_Traffic_Sign_Recognition.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "14HBuBFmljV7",
        "outputId": "17d17e8d-1e67-4b32-a5c9-493b95928f0c"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'APS360_Traffic_Sign_Recognition'...\n",
            "remote: Enumerating objects: 15398, done.\u001b[K\n",
            "remote: Counting objects: 100% (74/74), done.\u001b[K\n",
            "remote: Compressing objects: 100% (56/56), done.\u001b[K\n",
            "remote: Total 15398 (delta 30), reused 51 (delta 16), pack-reused 15324\u001b[K\n",
            "Receiving objects: 100% (15398/15398), 628.47 MiB | 40.61 MiB/s, done.\n",
            "Resolving deltas: 100% (71/71), done.\n",
            "Updating files: 100% (5347/5347), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#path csv with labels\n",
        "csv_path = \"/content/APS360_Traffic_Sign_Recognition/dataset_traffic_signs.csv\""
      ],
      "metadata": {
        "id": "yY6HmiZkljpY"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ObjectDetectionDataset(Dataset):\n",
        "    '''\n",
        "    A Pytorch Dataset class to load the images and their corresponding annotations.\n",
        "    \n",
        "    Returns\n",
        "    ------------\n",
        "    images: torch.Tensor of size (B, C, H, W)\n",
        "    gt bboxes: torch.Tensor of size (B, max_objects, 4)\n",
        "    gt classes: torch.Tensor of size (B, max_objects)\n",
        "    '''\n",
        "    def __init__(self, csv_path, img_size, name2idx):\n",
        "        self.annotation_path = csv_path\n",
        "        self.img_size = img_size\n",
        "        self.name2idx = name2idx\n",
        "        \n",
        "        self.img_data_all, self.gt_bboxes_all, self.gt_classes_all = self.get_data()\n",
        "        \n",
        "    def __len__(self):\n",
        "        return self.img_data_all.size(dim=0)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        return self.img_data_all[idx], self.gt_bboxes_all[idx], self.gt_classes_all[idx]\n",
        "        \n",
        "    def get_data(self):\n",
        "        img_data_all = []\n",
        "        gt_idxs_all = []\n",
        "        \n",
        "        gt_boxes_all, gt_classes_all, img_paths = parse_annotation(self.annotation_path, self.img_size)\n",
        "        \n",
        "        for i, img_path in tqdm(enumerate(img_paths), total=len(img_paths)):\n",
        "      \n",
        "            # skip if the image path is not valid\n",
        "            if (not img_path) or (not os.path.exists(img_path)):\n",
        "                continue\n",
        "            \n",
        "            # read and resize image\n",
        "            \n",
        "            img = io.imread(img_path)\n",
        "            img = resize(img, self.img_size)\n",
        "            \n",
        "            # convert image to torch tensor and reshape it so channels come first\n",
        "            img_tensor = torch.from_numpy(img).permute(2, 0, 1)\n",
        "            \n",
        "            # encode class names as integers\n",
        "            gt_classes = gt_classes_all[i]\n",
        "            gt_idx = torch.Tensor([self.name2idx[name] for name in gt_classes])\n",
        "            \n",
        "            img_data_all.append(img_tensor)\n",
        "            gt_idxs_all.append(gt_idx)\n",
        "        \n",
        "        # pad bounding boxes and classes so they are of the same size\n",
        "\n",
        "        if len(gt_boxes_all)!=0 and len(gt_idxs_all)!=0 :\n",
        "          \n",
        "          gt_bboxes_pad = pad_sequence(gt_boxes_all, batch_first=True, padding_value=-1)\n",
        "          gt_classes_pad = pad_sequence(gt_idxs_all, batch_first=True, padding_value=-1)\n",
        "        \n",
        "        # stack all images\n",
        "        img_data_stacked = torch.stack(img_data_all)[:, :3, :, :]\n",
        "        \n",
        "        return img_data_stacked.to(dtype=torch.float32), gt_bboxes_pad, gt_classes_pad\n",
        "\n",
        "    def __getstate__(self):\n",
        "        state = self.__dict__.copy()\n",
        "        state['img_data_all'] = pickle.dumps(state['img_data_all'])\n",
        "        state['gt_bboxes_all'] = pickle.dumps(state['gt_bboxes_all'])\n",
        "        state['gt_classes_all'] = pickle.dumps(state['gt_classes_all'])\n",
        "        return state\n",
        "\n",
        "    def __setstate__(self, state):\n",
        "        state['img_data_all'] = pickle.loads(state['img_data_all'])\n",
        "        state['gt_bboxes_all'] = pickle.loads(state['gt_bboxes_all'])\n",
        "        state['gt_classes_all'] = pickle.loads(state['gt_classes_all'])\n",
        "        self.__dict__.update(state)"
      ],
      "metadata": {
        "id": "C3VecuNmloIZ"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img_width = 128\n",
        "img_height = 128\n",
        "csv_path = \"/content/APS360_Traffic_Sign_Recognition/dataset_traffic_signs.csv\"\n",
        "image_dir = os.path.join(\"data\", \"images\")\n",
        "name2idx = {'pad': -1, '30kmh': 0,'60kmh':1, '100kmh' : 2, 'yield': 3, 'keepRight' :4, 'NoEntry':5, 'NoLeft': 6, 'Stop':7, 'noRight':8, 'ChildrenCrossing' :9 }\n",
        "idx2name = {v:k for k, v in name2idx.items()}"
      ],
      "metadata": {
        "id": "YYCljhqhlxvE"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Load the custom modules on colab based on the files on git\n",
        "import sys\n",
        " #To use on colab\n",
        "sys.path.append('/content/APS360_Traffic_Sign_Recognition')\n",
        "\n",
        "# might be neccessary to change to from RCNN_model.utils import * in model\n",
        "#from RCNN_model.model import *\n",
        "from RCNN_model.utils import *"
      ],
      "metadata": {
        "id": "fDsfGr_Yl1j5"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision\n",
        "from torchvision import ops\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "\n",
        "#from utils import *\n",
        "\n",
        "class FeatureExtractor(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        model = torchvision.models.resnet50(pretrained=True)\n",
        "        req_layers = list(model.children())[:8]\n",
        "        self.backbone = nn.Sequential(*req_layers)\n",
        "        for param in self.backbone.named_parameters():\n",
        "            param[1].requires_grad = True\n",
        "        \n",
        "    def forward(self, img_data):\n",
        "        return self.backbone(img_data)\n",
        "    \n",
        "    def freeze_layers(self, num_layers):\n",
        "        for i, child in enumerate(self.backbone.children()):\n",
        "            if i < num_layers:\n",
        "                for param in child.parameters():\n",
        "                    param.requires_grad = False\n",
        "            else:\n",
        "                break\n",
        "        \n",
        "\n",
        "class ProposalModule(nn.Module):\n",
        "    def __init__(self, in_features, hidden_dim=128, n_anchors=9, p_dropout=0.3):\n",
        "        super().__init__()\n",
        "        self.n_anchors = n_anchors\n",
        "        self.conv1 = nn.Conv2d(in_features, hidden_dim, kernel_size=3, padding=1)\n",
        "        self.dropout = nn.Dropout(p_dropout)\n",
        "        self.conf_head = nn.Conv2d(hidden_dim, n_anchors, kernel_size=1)\n",
        "        self.reg_head = nn.Conv2d(hidden_dim, n_anchors * 4, kernel_size=1)\n",
        "        \n",
        "    def forward(self, feature_map, pos_anc_ind=None, neg_anc_ind=None, pos_anc_coords=None):\n",
        "        # determine mode\n",
        "        if pos_anc_ind is None or neg_anc_ind is None or pos_anc_coords is None:\n",
        "            mode = 'eval'\n",
        "        else:\n",
        "            mode = 'train'\n",
        "            \n",
        "        out = self.conv1(feature_map)\n",
        "        out = F.relu(self.dropout(out))\n",
        "        \n",
        "        reg_offsets_pred = self.reg_head(out) # (B, A*4, hmap, wmap)\n",
        "        conf_scores_pred = self.conf_head(out) # (B, A, hmap, wmap)\n",
        "        \n",
        "        if mode == 'train': \n",
        "            # get conf scores \n",
        "            conf_scores_pos = conf_scores_pred.flatten()[pos_anc_ind]\n",
        "            conf_scores_neg = conf_scores_pred.flatten()[neg_anc_ind]\n",
        "            # get offsets for +ve anchors\n",
        "            offsets_pos = reg_offsets_pred.contiguous().view(-1, 4)[pos_anc_ind]\n",
        "            # generate proposals using offsets\n",
        "            proposals = generate_proposals(pos_anc_coords, offsets_pos)\n",
        "            \n",
        "            return conf_scores_pos, conf_scores_neg, offsets_pos, proposals\n",
        "            \n",
        "        elif mode == 'eval':\n",
        "            return conf_scores_pred, reg_offsets_pred\n",
        "           \n",
        "class RegionProposalNetwork(nn.Module):\n",
        "    def __init__(self, img_size, out_size, out_channels):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.img_height, self.img_width = img_size\n",
        "        self.out_h, self.out_w = out_size\n",
        "        \n",
        "        # downsampling scale factor \n",
        "        self.width_scale_factor = self.img_width // self.out_w\n",
        "        self.height_scale_factor = self.img_height // self.out_h \n",
        "        \n",
        "        # scales and ratios for anchor boxes\n",
        "        self.anc_scales = [2, 4, 6]\n",
        "        self.anc_ratios = [0.5, 1, 1.5]\n",
        "        self.n_anc_boxes = len(self.anc_scales) * len(self.anc_ratios)\n",
        "        \n",
        "        # IoU thresholds for +ve and -ve anchors\n",
        "        self.pos_thresh = 0.7\n",
        "        self.neg_thresh = 0.3\n",
        "        \n",
        "        # weights for loss\n",
        "        self.w_conf = 1\n",
        "        self.w_reg = 5\n",
        "        \n",
        "        self.feature_extractor = FeatureExtractor()\n",
        "        #freezing the first 6 layers\n",
        "        self.feature_extractor.freeze_layers(8)\n",
        "        self.proposal_module = ProposalModule(out_channels, n_anchors=self.n_anc_boxes)\n",
        "        \n",
        "    def forward(self, images, gt_bboxes, gt_classes):\n",
        "        batch_size = images.size(dim=0)\n",
        "        feature_map = self.feature_extractor(images)\n",
        "        \n",
        "        # generate anchors\n",
        "        anc_pts_x, anc_pts_y = gen_anc_centers(out_size=(self.out_h, self.out_w))\n",
        "        anc_base = gen_anc_base(anc_pts_x, anc_pts_y, self.anc_scales, self.anc_ratios, (self.out_h, self.out_w))\n",
        "        anc_boxes_all = anc_base.repeat(batch_size, 1, 1, 1, 1)\n",
        "        \n",
        "        # get positive and negative anchors amongst other things\n",
        "        gt_bboxes_proj = project_bboxes(gt_bboxes, self.width_scale_factor, self.height_scale_factor, mode='p2a')\n",
        "        \n",
        "        positive_anc_ind, negative_anc_ind, GT_conf_scores, \\\n",
        "        GT_offsets, GT_class_pos, positive_anc_coords, \\\n",
        "        negative_anc_coords, positive_anc_ind_sep = get_req_anchors(anc_boxes_all, gt_bboxes_proj, gt_classes)\n",
        "        \n",
        "        # pass through the proposal module\n",
        "        conf_scores_pos, conf_scores_neg, offsets_pos, proposals = self.proposal_module(feature_map, positive_anc_ind, \\\n",
        "                                                                                        negative_anc_ind, positive_anc_coords)\n",
        "        \n",
        "        cls_loss = calc_cls_loss(conf_scores_pos, conf_scores_neg, batch_size)\n",
        "        reg_loss = calc_bbox_reg_loss(GT_offsets, offsets_pos, batch_size)\n",
        "        \n",
        "        total_rpn_loss = self.w_conf * cls_loss + self.w_reg * reg_loss\n",
        "        \n",
        "        return total_rpn_loss, feature_map, proposals, positive_anc_ind_sep, GT_class_pos\n",
        "\n",
        "    def inference(self, images, conf_thresh=0.5, nms_thresh=0.7):\n",
        "        with torch.no_grad():\n",
        "            batch_size = images.size(dim=0)\n",
        "            feature_map = self.feature_extractor(images)\n",
        "\n",
        "            # generate anchors\n",
        "            anc_pts_x, anc_pts_y = gen_anc_centers(out_size=(self.out_h, self.out_w))\n",
        "            anc_base = gen_anc_base(anc_pts_x, anc_pts_y, self.anc_scales, self.anc_ratios, (self.out_h, self.out_w))\n",
        "            anc_boxes_all = anc_base.repeat(batch_size, 1, 1, 1, 1)\n",
        "            anc_boxes_flat = anc_boxes_all.reshape(batch_size, -1, 4)\n",
        "\n",
        "            # get conf scores and offsets\n",
        "            conf_scores_pred, offsets_pred = self.proposal_module(feature_map)\n",
        "            conf_scores_pred = conf_scores_pred.reshape(batch_size, -1)\n",
        "            offsets_pred = offsets_pred.reshape(batch_size, -1, 4)\n",
        "\n",
        "            # filter out proposals based on conf threshold and nms threshold for each image\n",
        "            proposals_final = []\n",
        "            conf_scores_final = []\n",
        "            for i in range(batch_size):\n",
        "                conf_scores = torch.sigmoid(conf_scores_pred[i])\n",
        "                offsets = offsets_pred[i]\n",
        "                anc_boxes = anc_boxes_flat[i]\n",
        "                proposals = generate_proposals(anc_boxes, offsets)\n",
        "                # filter based on confidence threshold\n",
        "                conf_idx = torch.where(conf_scores >= conf_thresh)[0]\n",
        "                conf_scores_pos = conf_scores[conf_idx]\n",
        "                proposals_pos = proposals[conf_idx]\n",
        "                # filter based on nms threshold\n",
        "                nms_idx = ops.nms(proposals_pos, conf_scores_pos, nms_thresh)\n",
        "                conf_scores_pos = conf_scores_pos[nms_idx]\n",
        "                proposals_pos = proposals_pos[nms_idx]\n",
        "\n",
        "                proposals_final.append(proposals_pos)\n",
        "                conf_scores_final.append(conf_scores_pos)\n",
        "            \n",
        "        return proposals_final, conf_scores_final, feature_map\n",
        "    \n",
        "class ClassificationModule(nn.Module):\n",
        "    def __init__(self, out_channels, n_classes, roi_size, hidden_dim=64, p_dropout=0.3):\n",
        "        super().__init__()        \n",
        "        self.roi_size = roi_size\n",
        "        # hidden network\n",
        "        self.avg_pool = nn.AvgPool2d(self.roi_size)\n",
        "        self.fc = nn.Linear(out_channels, hidden_dim)\n",
        "        self.dropout = nn.Dropout(p_dropout)\n",
        "        \n",
        "        # define classification head\n",
        "        self.cls_head = nn.Linear(hidden_dim, n_classes)\n",
        "        \n",
        "    def forward(self, feature_map, proposals_list, gt_classes=None):\n",
        "        \n",
        "        if gt_classes is None:\n",
        "            mode = 'eval'\n",
        "        else:\n",
        "            mode = 'train'\n",
        "        \n",
        "        # apply roi pooling on proposals followed by avg pooling\n",
        "        roi_out = ops.roi_pool(feature_map, proposals_list, self.roi_size)\n",
        "        roi_out = self.avg_pool(roi_out)\n",
        "        \n",
        "        # flatten the output\n",
        "        roi_out = roi_out.squeeze(-1).squeeze(-1)\n",
        "        \n",
        "        # pass the output through the hidden network\n",
        "        out = self.fc(roi_out)\n",
        "        out = F.relu(self.dropout(out))\n",
        "        \n",
        "        # get the classification scores\n",
        "        cls_scores = self.cls_head(out)\n",
        "        \n",
        "        if mode == 'eval':\n",
        "            return cls_scores\n",
        "        \n",
        "        # compute cross entropy loss\n",
        "        cls_loss = F.cross_entropy(cls_scores, gt_classes.long())\n",
        "        \n",
        "        return cls_loss\n",
        "    \n",
        "class TwoStageDetector(nn.Module):\n",
        "    def __init__(self, img_size, out_size, out_channels, n_classes, roi_size):\n",
        "        super().__init__() \n",
        "        self.rpn = RegionProposalNetwork(img_size, out_size, out_channels)\n",
        "        self.classifier = ClassificationModule(out_channels, n_classes, roi_size)\n",
        "        \n",
        "    def forward(self, images, gt_bboxes, gt_classes):\n",
        "        total_rpn_loss, feature_map, proposals, \\\n",
        "        positive_anc_ind_sep, GT_class_pos = self.rpn(images, gt_bboxes, gt_classes)\n",
        "        \n",
        "        # get separate proposals for each sample\n",
        "        pos_proposals_list = []\n",
        "        batch_size = images.size(dim=0)\n",
        "        for idx in range(batch_size):\n",
        "            proposal_idxs = torch.where(positive_anc_ind_sep == idx)[0]\n",
        "            proposals_sep = proposals[proposal_idxs].detach().clone()\n",
        "            pos_proposals_list.append(proposals_sep)\n",
        "        \n",
        "        cls_loss = self.classifier(feature_map, pos_proposals_list, GT_class_pos)\n",
        "        total_loss = cls_loss + total_rpn_loss\n",
        "        \n",
        "        return total_loss\n",
        "    \n",
        "    def inference(self, images, conf_thresh=0.5, nms_thresh=0.7):\n",
        "        batch_size = images.size(dim=0)\n",
        "        proposals_final, conf_scores_final, feature_map = self.rpn.inference(images, conf_thresh, nms_thresh)\n",
        "        cls_scores = self.classifier(feature_map, proposals_final)\n",
        "        \n",
        "        # convert scores into probability\n",
        "        cls_probs = F.softmax(cls_scores, dim=-1)\n",
        "        # get classes with highest probability\n",
        "        classes_all = torch.argmax(cls_probs, dim=-1)\n",
        "        \n",
        "        classes_final = []\n",
        "        # slice classes to map to their corresponding image\n",
        "        c = 0\n",
        "        for i in range(batch_size):\n",
        "            n_proposals = len(proposals_final[i]) # get the number of proposals for each image\n",
        "            classes_final.append(classes_all[c: c+n_proposals])\n",
        "            c += n_proposals\n",
        "            \n",
        "        return proposals_final, conf_scores_final, classes_final\n",
        "\n",
        "# ------------------- Loss Utils ----------------------\n",
        "def calc_cls_loss(conf_scores_pos, conf_scores_neg, batch_size):\n",
        "    \"\"\"\n",
        "    Calculate the classification loss (binary cross-entropy loss) for the RPN.\n",
        "\n",
        "    Args:\n",
        "        conf_scores_pos (Tensor): the predicted class scores for the positive anchors\n",
        "        conf_scores_neg (Tensor): the predicted class scores for the negative anchors\n",
        "        batch_size (int): the number of samples in the batch\n",
        "\n",
        "    Returns:\n",
        "        Tensor: the binary cross-entropy loss\n",
        "    \"\"\"\n",
        "\n",
        "    # concatenate the positive and negative scores\n",
        "    inputs = torch.cat((conf_scores_pos, conf_scores_neg), dim=0)\n",
        "\n",
        "    # create the target tensor\n",
        "    target = torch.cat((torch.ones(conf_scores_pos.shape[0], dtype=torch.float), \n",
        "                        torch.zeros(conf_scores_neg.shape[0], dtype=torch.float)), dim=0)\n",
        "\n",
        "    # convert the target tensor to float\n",
        "    target = target.float()\n",
        "\n",
        "    # calculate binary cross entropy loss\n",
        "    loss_fn = nn.CrossEntropyLoss(weight=None, reduction='mean')\n",
        "    loss = loss_fn(inputs, target)\n",
        "    clip_value = 1e8\n",
        "    if clip_value is not None:\n",
        "        torch.nn.utils.clip_grad_norm_(loss_fn.parameters(), clip_value) \n",
        "\n",
        "    return loss\n",
        "\n",
        "\n",
        "#def calc_cls_loss(conf_scores_pos, conf_scores_neg, batch_size):\n",
        "    #target_pos = torch.ones_like(conf_scores_pos)\n",
        "    #target_neg = torch.zeros_like(conf_scores_neg)\n",
        "    \n",
        "    #target = torch.cat((target_pos, target_neg))\n",
        "    #inputs = torch.cat((conf_scores_pos, conf_scores_neg))\n",
        "     \n",
        "    #loss = F.binary_cross_entropy_with_logits(inputs, target, reduction='sum') * 1. / batch_size\n",
        "    #loss_fn = nn.CrossEntropyLoss(inputs, target, reduction = 'sum')*1./batch_size\n",
        "    #return loss_fn\n",
        "\n",
        "def calc_bbox_reg_loss(gt_offsets, reg_offsets_pos, batch_size):\n",
        "    assert gt_offsets.size() == reg_offsets_pos.size()\n",
        "    loss = F.smooth_l1_loss(reg_offsets_pos, gt_offsets, reduction='sum') * 1. / batch_size\n",
        "    return loss\n",
        "\n"
      ],
      "metadata": {
        "id": "E9YEONkpmAAe"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#function taken from tutorial 3b\n",
        "def get_accuracy(model, data):\n",
        "    \n",
        "    correct = 0\n",
        "    total = 0\n",
        "    model.eval() #*********#\n",
        "    dataloader = DataLoader(data, batch_size=64)\n",
        "    for img_batch, gt_bboxes_batch, gt_classes_batch in tqdm(dataloader):\n",
        "        proposals_final, conf_scores_final, classes_final = model.inference(img_batch, conf_thresh=0.90, nms_thresh=0.05)\n",
        "        \n",
        "        for i in range(len(gt_classes_batch)):\n",
        "                y_true = gt_classes_batch[i]\n",
        "                 # check if the tensor is empty\n",
        "                if conf_scores_final[1].numel() == 0:\n",
        "                  continue\n",
        "                idx = torch.argmax(conf_scores_final[1])\n",
        "                current_class_ = classes_final[1][idx]\n",
        "                current_class = current_class_.unsqueeze(0)\n",
        "                if current_class.item()== y_true.item():\n",
        "                  correct += 1\n",
        "                total += 1\n",
        "    return correct/total\n"
      ],
      "metadata": {
        "id": "evVvxL_51Tbf"
      },
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "get_accuracy(detector, val_dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TgSpgb_38j6j",
        "outputId": "c49301de-4251-49fe-d360-1b0a805e7ca1"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10/10 [00:38<00:00,  3.88s/it]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.15141955835962145"
            ]
          },
          "metadata": {},
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "datset = ObjectDetectionDataset(csv_path, (img_height, img_width), name2idx)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mcqQKdSMm-dk",
        "outputId": "73c24755-df35-4337-b46d-cc0704686486"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3688/3688 [00:30<00:00, 121.58it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "od_dataloader = DataLoader(datset, batch_size=32)"
      ],
      "metadata": {
        "id": "NsrUgR9xnBtr"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img_size = (img_height, img_width)\n",
        "out_size = (4,4) ## see other d\n",
        "n_classes = len(name2idx) - 1 # exclude pad idx\n",
        "roi_size = (2, 2)\n",
        "out_c = 2048"
      ],
      "metadata": {
        "id": "rv74BuVKnrBi"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "detector = TwoStageDetector(img_size, out_size, out_c, n_classes, roi_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KVkMz6rNt8SP",
        "outputId": "5965a2ab-2400-44f8-d478-fba26e2d4a94"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rate = 1e-2\n",
        "n_epochs = 2\n",
        "loss_list = training_loop(detector, learning_rate, od_dataloader, n_epochs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FY3HTovLuKZS",
        "outputId": "231a8e77-9696-4cf3-cef4-79783d9babc0"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/2 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "iteration 0\n",
            "loss tensor(10.8066, grad_fn=<AddBackward0>)\n",
            "iteration 0\n",
            "loss tensor(561.8773, grad_fn=<AddBackward0>)\n",
            "iteration 0\n",
            "loss tensor(2214.8215, grad_fn=<AddBackward0>)\n",
            "iteration 0\n",
            "loss tensor(2078.7554, grad_fn=<AddBackward0>)\n",
            "iteration 0\n",
            "loss tensor(691.8011, grad_fn=<AddBackward0>)\n",
            "iteration 0\n",
            "loss tensor(309.1836, grad_fn=<AddBackward0>)\n",
            "iteration 0\n",
            "loss tensor(47.9379, grad_fn=<AddBackward0>)\n",
            "iteration 0\n",
            "loss tensor(145.9836, grad_fn=<AddBackward0>)\n",
            "iteration 0\n",
            "loss tensor(7.6316, grad_fn=<AddBackward0>)\n",
            "iteration 0\n",
            "loss tensor(168.1086, grad_fn=<AddBackward0>)\n",
            "iteration 0\n",
            "loss tensor(18.2922, grad_fn=<AddBackward0>)\n",
            "iteration 0\n",
            "loss tensor(63.2084, grad_fn=<AddBackward0>)\n",
            "iteration 0\n",
            "loss tensor(10.7894, grad_fn=<AddBackward0>)\n",
            "iteration 0\n",
            "loss tensor(62.7178, grad_fn=<AddBackward0>)\n",
            "iteration 0\n",
            "loss tensor(nan, grad_fn=<AddBackward0>)\n",
            "Skipping NaN loss\n",
            "iteration 0\n",
            "loss tensor(287.0280, grad_fn=<AddBackward0>)\n",
            "iteration 0\n",
            "loss tensor(nan, grad_fn=<AddBackward0>)\n",
            "Skipping NaN loss\n",
            "iteration 0\n",
            "loss tensor(273.7249, grad_fn=<AddBackward0>)\n",
            "iteration 0\n",
            "loss tensor(nan, grad_fn=<AddBackward0>)\n",
            "Skipping NaN loss\n",
            "iteration 0\n",
            "loss tensor(336.3222, grad_fn=<AddBackward0>)\n",
            "iteration 0\n",
            "loss tensor(12.4705, grad_fn=<AddBackward0>)\n",
            "iteration 0\n",
            "loss tensor(91.5440, grad_fn=<AddBackward0>)\n",
            "iteration 0\n",
            "loss tensor(nan, grad_fn=<AddBackward0>)\n",
            "Skipping NaN loss\n",
            "iteration 0\n",
            "loss tensor(155.7878, grad_fn=<AddBackward0>)\n",
            "iteration 0\n",
            "loss tensor(164.9726, grad_fn=<AddBackward0>)\n",
            "iteration 0\n",
            "loss tensor(45.8656, grad_fn=<AddBackward0>)\n",
            "iteration 0\n",
            "loss tensor(420.6594, grad_fn=<AddBackward0>)\n",
            "iteration 0\n",
            "loss tensor(nan, grad_fn=<AddBackward0>)\n",
            "Skipping NaN loss\n",
            "iteration 0\n",
            "loss tensor(12.1741, grad_fn=<AddBackward0>)\n",
            "iteration 0\n",
            "loss tensor(121.5024, grad_fn=<AddBackward0>)\n",
            "iteration 0\n",
            "loss tensor(8.4436, grad_fn=<AddBackward0>)\n",
            "iteration 0\n",
            "loss tensor(87.8535, grad_fn=<AddBackward0>)\n",
            "iteration 0\n",
            "loss tensor(6.2070, grad_fn=<AddBackward0>)\n",
            "iteration 0\n",
            "loss tensor(nan, grad_fn=<AddBackward0>)\n",
            "Skipping NaN loss\n",
            "iteration 0\n",
            "loss tensor(36.2658, grad_fn=<AddBackward0>)\n",
            "iteration 0\n",
            "loss tensor(18.7400, grad_fn=<AddBackward0>)\n",
            "iteration 0\n",
            "loss tensor(100.0519, grad_fn=<AddBackward0>)\n",
            "iteration 0\n",
            "loss tensor(38.2948, grad_fn=<AddBackward0>)\n",
            "iteration 0\n",
            "loss tensor(nan, grad_fn=<AddBackward0>)\n",
            "Skipping NaN loss\n",
            "iteration 0\n",
            "loss tensor(11.4386, grad_fn=<AddBackward0>)\n",
            "iteration 0\n",
            "loss tensor(280.9445, grad_fn=<AddBackward0>)\n",
            "iteration 0\n",
            "loss tensor(123.7407, grad_fn=<AddBackward0>)\n",
            "iteration 0\n",
            "loss tensor(nan, grad_fn=<AddBackward0>)\n",
            "Skipping NaN loss\n",
            "iteration 0\n",
            "loss tensor(nan, grad_fn=<AddBackward0>)\n",
            "Skipping NaN loss\n",
            "iteration 0\n",
            "loss tensor(327.8716, grad_fn=<AddBackward0>)\n",
            "iteration 0\n",
            "loss tensor(34.2938, grad_fn=<AddBackward0>)\n",
            "iteration 0\n",
            "loss tensor(nan, grad_fn=<AddBackward0>)\n",
            "Skipping NaN loss\n",
            "iteration 0\n",
            "loss tensor(nan, grad_fn=<AddBackward0>)\n",
            "Skipping NaN loss\n",
            "iteration 0\n",
            "loss tensor(nan, grad_fn=<AddBackward0>)\n",
            "Skipping NaN loss\n",
            "iteration 0\n",
            "loss tensor(35.1293, grad_fn=<AddBackward0>)\n",
            "iteration 0\n",
            "loss tensor(nan, grad_fn=<AddBackward0>)\n",
            "Skipping NaN loss\n",
            "iteration 0\n",
            "loss tensor(nan, grad_fn=<AddBackward0>)\n",
            "Skipping NaN loss\n",
            "iteration 0\n",
            "loss tensor(nan, grad_fn=<AddBackward0>)\n",
            "Skipping NaN loss\n",
            "iteration 0\n",
            "loss tensor(nan, grad_fn=<AddBackward0>)\n",
            "Skipping NaN loss\n",
            "iteration 0\n",
            "loss tensor(nan, grad_fn=<AddBackward0>)\n",
            "Skipping NaN loss\n",
            "iteration 0\n",
            "loss tensor(nan, grad_fn=<AddBackward0>)\n",
            "Skipping NaN loss\n",
            "iteration 0\n",
            "loss tensor(nan, grad_fn=<AddBackward0>)\n",
            "Skipping NaN loss\n",
            "iteration 0\n",
            "loss tensor(nan, grad_fn=<AddBackward0>)\n",
            "Skipping NaN loss\n",
            "iteration 0\n",
            "loss tensor(nan, grad_fn=<AddBackward0>)\n",
            "Skipping NaN loss\n",
            "iteration 0\n",
            "loss tensor(118.8146, grad_fn=<AddBackward0>)\n",
            "iteration 0\n",
            "loss tensor(175.6117, grad_fn=<AddBackward0>)\n",
            "iteration 0\n",
            "loss tensor(100.2085, grad_fn=<AddBackward0>)\n",
            "iteration 0\n",
            "loss tensor(400.3653, grad_fn=<AddBackward0>)\n",
            "iteration 0\n",
            "loss tensor(25.8006, grad_fn=<AddBackward0>)\n",
            "iteration 0\n",
            "loss tensor(14.1366, grad_fn=<AddBackward0>)\n",
            "iteration 0\n",
            "loss tensor(67.0142, grad_fn=<AddBackward0>)\n",
            "iteration 0\n",
            "loss tensor(195.9473, grad_fn=<AddBackward0>)\n",
            "iteration 0\n",
            "loss tensor(8.5277, grad_fn=<AddBackward0>)\n",
            "iteration 0\n",
            "loss tensor(88.1256, grad_fn=<AddBackward0>)\n",
            "iteration 0\n",
            "loss tensor(5.2791, grad_fn=<AddBackward0>)\n",
            "iteration 0\n",
            "loss tensor(236.9939, grad_fn=<AddBackward0>)\n",
            "iteration 0\n",
            "loss tensor(43.8671, grad_fn=<AddBackward0>)\n",
            "iteration 0\n",
            "loss tensor(152.8635, grad_fn=<AddBackward0>)\n",
            "iteration 0\n",
            "loss tensor(123.4413, grad_fn=<AddBackward0>)\n",
            "iteration 0\n",
            "loss tensor(202.6517, grad_fn=<AddBackward0>)\n",
            "iteration 0\n",
            "loss tensor(99.4580, grad_fn=<AddBackward0>)\n",
            "iteration 0\n",
            "loss tensor(28.1586, grad_fn=<AddBackward0>)\n",
            "iteration 0\n",
            "loss tensor(2.9311, grad_fn=<AddBackward0>)\n",
            "iteration 0\n",
            "loss tensor(132.7487, grad_fn=<AddBackward0>)\n",
            "iteration 0\n",
            "loss tensor(93.2165, grad_fn=<AddBackward0>)\n",
            "iteration 0\n",
            "loss tensor(37.5975, grad_fn=<AddBackward0>)\n",
            "iteration 0\n",
            "loss tensor(40.4898, grad_fn=<AddBackward0>)\n",
            "iteration 0\n",
            "loss tensor(6.9016, grad_fn=<AddBackward0>)\n",
            "iteration 0\n",
            "loss tensor(36.4484, grad_fn=<AddBackward0>)\n",
            "iteration 0\n",
            "loss tensor(22.9235, grad_fn=<AddBackward0>)\n",
            "iteration 0\n",
            "loss tensor(10.9989, grad_fn=<AddBackward0>)\n",
            "iteration 0\n",
            "loss tensor(40.5576, grad_fn=<AddBackward0>)\n",
            "iteration 0\n",
            "loss tensor(16.7060, grad_fn=<AddBackward0>)\n",
            "iteration 0\n",
            "loss tensor(57.7117, grad_fn=<AddBackward0>)\n",
            "iteration 0\n",
            "loss tensor(30.9748, grad_fn=<AddBackward0>)\n",
            "iteration 0\n",
            "loss tensor(25.3788, grad_fn=<AddBackward0>)\n",
            "iteration 0\n",
            "loss tensor(52.7747, grad_fn=<AddBackward0>)\n",
            "iteration 0\n",
            "loss tensor(nan, grad_fn=<AddBackward0>)\n",
            "Skipping NaN loss\n",
            "iteration 0\n",
            "loss tensor(2.8920, grad_fn=<AddBackward0>)\n",
            "iteration 0\n",
            "loss tensor(2.7804, grad_fn=<AddBackward0>)\n",
            "iteration 0\n",
            "loss tensor(nan, grad_fn=<AddBackward0>)\n",
            "Skipping NaN loss\n",
            "iteration 0\n",
            "loss tensor(nan, grad_fn=<AddBackward0>)\n",
            "Skipping NaN loss\n",
            "iteration 0\n",
            "loss tensor(15.2905, grad_fn=<AddBackward0>)\n",
            "iteration 0\n",
            "loss tensor(nan, grad_fn=<AddBackward0>)\n",
            "Skipping NaN loss\n",
            "iteration 0\n",
            "loss tensor(2.7376, grad_fn=<AddBackward0>)\n",
            "iteration 0\n",
            "loss tensor(nan, grad_fn=<AddBackward0>)\n",
            "Skipping NaN loss\n",
            "iteration 0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 50%|█████     | 1/2 [04:03<04:03, 243.58s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss tensor(nan, grad_fn=<AddBackward0>)\n",
            "Skipping NaN loss\n",
            "iteration 1\n",
            "loss tensor(34.8989, grad_fn=<AddBackward0>)\n",
            "iteration 1\n",
            "loss tensor(225.6290, grad_fn=<AddBackward0>)\n",
            "iteration 1\n",
            "loss tensor(142.9758, grad_fn=<AddBackward0>)\n",
            "iteration 1\n",
            "loss tensor(409.4698, grad_fn=<AddBackward0>)\n",
            "iteration 1\n",
            "loss tensor(119.5104, grad_fn=<AddBackward0>)\n",
            "iteration 1\n",
            "loss tensor(58.1959, grad_fn=<AddBackward0>)\n",
            "iteration 1\n",
            "loss tensor(10.0574, grad_fn=<AddBackward0>)\n",
            "iteration 1\n",
            "loss tensor(5.5498, grad_fn=<AddBackward0>)\n",
            "iteration 1\n",
            "loss tensor(2.8526, grad_fn=<AddBackward0>)\n",
            "iteration 1\n",
            "loss tensor(19.9750, grad_fn=<AddBackward0>)\n",
            "iteration 1\n",
            "loss tensor(2.2267, grad_fn=<AddBackward0>)\n",
            "iteration 1\n",
            "loss tensor(71.7837, grad_fn=<AddBackward0>)\n",
            "iteration 1\n",
            "loss tensor(0.1548, grad_fn=<AddBackward0>)\n",
            "iteration 1\n",
            "loss tensor(6.7257, grad_fn=<AddBackward0>)\n",
            "iteration 1\n",
            "loss tensor(nan, grad_fn=<AddBackward0>)\n",
            "Skipping NaN loss\n",
            "iteration 1\n",
            "loss tensor(27.7759, grad_fn=<AddBackward0>)\n",
            "iteration 1\n",
            "loss tensor(nan, grad_fn=<AddBackward0>)\n",
            "Skipping NaN loss\n",
            "iteration 1\n",
            "loss tensor(26.0428, grad_fn=<AddBackward0>)\n",
            "iteration 1\n",
            "loss tensor(nan, grad_fn=<AddBackward0>)\n",
            "Skipping NaN loss\n",
            "iteration 1\n",
            "loss tensor(42.9469, grad_fn=<AddBackward0>)\n",
            "iteration 1\n",
            "loss tensor(2.5552, grad_fn=<AddBackward0>)\n",
            "iteration 1\n",
            "loss tensor(6.5654, grad_fn=<AddBackward0>)\n",
            "iteration 1\n",
            "loss tensor(nan, grad_fn=<AddBackward0>)\n",
            "Skipping NaN loss\n",
            "iteration 1\n",
            "loss tensor(20.4061, grad_fn=<AddBackward0>)\n",
            "iteration 1\n",
            "loss tensor(16.5893, grad_fn=<AddBackward0>)\n",
            "iteration 1\n",
            "loss tensor(24.9412, grad_fn=<AddBackward0>)\n",
            "iteration 1\n",
            "loss tensor(13.5456, grad_fn=<AddBackward0>)\n",
            "iteration 1\n",
            "loss tensor(nan, grad_fn=<AddBackward0>)\n",
            "Skipping NaN loss\n",
            "iteration 1\n",
            "loss tensor(3.2518, grad_fn=<AddBackward0>)\n",
            "iteration 1\n",
            "loss tensor(22.5606, grad_fn=<AddBackward0>)\n",
            "iteration 1\n",
            "loss tensor(4.5584, grad_fn=<AddBackward0>)\n",
            "iteration 1\n",
            "loss tensor(5.9780, grad_fn=<AddBackward0>)\n",
            "iteration 1\n",
            "loss tensor(3.3965, grad_fn=<AddBackward0>)\n",
            "iteration 1\n",
            "loss tensor(nan, grad_fn=<AddBackward0>)\n",
            "Skipping NaN loss\n",
            "iteration 1\n",
            "loss tensor(13.5030, grad_fn=<AddBackward0>)\n",
            "iteration 1\n",
            "loss tensor(2.9716, grad_fn=<AddBackward0>)\n",
            "iteration 1\n",
            "loss tensor(9.1489, grad_fn=<AddBackward0>)\n",
            "iteration 1\n",
            "loss tensor(5.9472, grad_fn=<AddBackward0>)\n",
            "iteration 1\n",
            "loss tensor(nan, grad_fn=<AddBackward0>)\n",
            "Skipping NaN loss\n",
            "iteration 1\n",
            "loss tensor(3.1189, grad_fn=<AddBackward0>)\n",
            "iteration 1\n",
            "loss tensor(2.9960, grad_fn=<AddBackward0>)\n",
            "iteration 1\n",
            "loss tensor(3.3900, grad_fn=<AddBackward0>)\n",
            "iteration 1\n",
            "loss tensor(nan, grad_fn=<AddBackward0>)\n",
            "Skipping NaN loss\n",
            "iteration 1\n",
            "loss tensor(nan, grad_fn=<AddBackward0>)\n",
            "Skipping NaN loss\n",
            "iteration 1\n",
            "loss tensor(13.8439, grad_fn=<AddBackward0>)\n",
            "iteration 1\n",
            "loss tensor(5.2093, grad_fn=<AddBackward0>)\n",
            "iteration 1\n",
            "loss tensor(nan, grad_fn=<AddBackward0>)\n",
            "Skipping NaN loss\n",
            "iteration 1\n",
            "loss tensor(nan, grad_fn=<AddBackward0>)\n",
            "Skipping NaN loss\n",
            "iteration 1\n",
            "loss tensor(nan, grad_fn=<AddBackward0>)\n",
            "Skipping NaN loss\n",
            "iteration 1\n",
            "loss tensor(6.0056, grad_fn=<AddBackward0>)\n",
            "iteration 1\n",
            "loss tensor(nan, grad_fn=<AddBackward0>)\n",
            "Skipping NaN loss\n",
            "iteration 1\n",
            "loss tensor(nan, grad_fn=<AddBackward0>)\n",
            "Skipping NaN loss\n",
            "iteration 1\n",
            "loss tensor(nan, grad_fn=<AddBackward0>)\n",
            "Skipping NaN loss\n",
            "iteration 1\n",
            "loss tensor(nan, grad_fn=<AddBackward0>)\n",
            "Skipping NaN loss\n",
            "iteration 1\n",
            "loss tensor(nan, grad_fn=<AddBackward0>)\n",
            "Skipping NaN loss\n",
            "iteration 1\n",
            "loss tensor(nan, grad_fn=<AddBackward0>)\n",
            "Skipping NaN loss\n",
            "iteration 1\n",
            "loss tensor(nan, grad_fn=<AddBackward0>)\n",
            "Skipping NaN loss\n",
            "iteration 1\n",
            "loss tensor(nan, grad_fn=<AddBackward0>)\n",
            "Skipping NaN loss\n",
            "iteration 1\n",
            "loss tensor(nan, grad_fn=<AddBackward0>)\n",
            "Skipping NaN loss\n",
            "iteration 1\n",
            "loss tensor(3.2288, grad_fn=<AddBackward0>)\n",
            "iteration 1\n",
            "loss tensor(13.1111, grad_fn=<AddBackward0>)\n",
            "iteration 1\n",
            "loss tensor(5.3045, grad_fn=<AddBackward0>)\n",
            "iteration 1\n",
            "loss tensor(23.7436, grad_fn=<AddBackward0>)\n",
            "iteration 1\n",
            "loss tensor(7.2093, grad_fn=<AddBackward0>)\n",
            "iteration 1\n",
            "loss tensor(4.9923, grad_fn=<AddBackward0>)\n",
            "iteration 1\n",
            "loss tensor(6.6932, grad_fn=<AddBackward0>)\n",
            "iteration 1\n",
            "loss tensor(12.6762, grad_fn=<AddBackward0>)\n",
            "iteration 1\n",
            "loss tensor(3.6325, grad_fn=<AddBackward0>)\n",
            "iteration 1\n",
            "loss tensor(5.9165, grad_fn=<AddBackward0>)\n",
            "iteration 1\n",
            "loss tensor(0.7952, grad_fn=<AddBackward0>)\n",
            "iteration 1\n",
            "loss tensor(106.1662, grad_fn=<AddBackward0>)\n",
            "iteration 1\n",
            "loss tensor(5.1291, grad_fn=<AddBackward0>)\n",
            "iteration 1\n",
            "loss tensor(6.1151, grad_fn=<AddBackward0>)\n",
            "iteration 1\n",
            "loss tensor(9.4364, grad_fn=<AddBackward0>)\n",
            "iteration 1\n",
            "loss tensor(22.5515, grad_fn=<AddBackward0>)\n",
            "iteration 1\n",
            "loss tensor(5.0953, grad_fn=<AddBackward0>)\n",
            "iteration 1\n",
            "loss tensor(37.5857, grad_fn=<AddBackward0>)\n",
            "iteration 1\n",
            "loss tensor(2.8745, grad_fn=<AddBackward0>)\n",
            "iteration 1\n",
            "loss tensor(27.8979, grad_fn=<AddBackward0>)\n",
            "iteration 1\n",
            "loss tensor(18.9088, grad_fn=<AddBackward0>)\n",
            "iteration 1\n",
            "loss tensor(32.7632, grad_fn=<AddBackward0>)\n",
            "iteration 1\n",
            "loss tensor(9.6065, grad_fn=<AddBackward0>)\n",
            "iteration 1\n",
            "loss tensor(10.3676, grad_fn=<AddBackward0>)\n",
            "iteration 1\n",
            "loss tensor(10.6184, grad_fn=<AddBackward0>)\n",
            "iteration 1\n",
            "loss tensor(11.3123, grad_fn=<AddBackward0>)\n",
            "iteration 1\n",
            "loss tensor(6.0180, grad_fn=<AddBackward0>)\n",
            "iteration 1\n",
            "loss tensor(9.8995, grad_fn=<AddBackward0>)\n",
            "iteration 1\n",
            "loss tensor(2.7039, grad_fn=<AddBackward0>)\n",
            "iteration 1\n",
            "loss tensor(13.5658, grad_fn=<AddBackward0>)\n",
            "iteration 1\n",
            "loss tensor(7.8706, grad_fn=<AddBackward0>)\n",
            "iteration 1\n",
            "loss tensor(4.8504, grad_fn=<AddBackward0>)\n",
            "iteration 1\n",
            "loss tensor(3.2556, grad_fn=<AddBackward0>)\n",
            "iteration 1\n",
            "loss tensor(nan, grad_fn=<AddBackward0>)\n",
            "Skipping NaN loss\n",
            "iteration 1\n",
            "loss tensor(3.3378, grad_fn=<AddBackward0>)\n",
            "iteration 1\n",
            "loss tensor(3.0754, grad_fn=<AddBackward0>)\n",
            "iteration 1\n",
            "loss tensor(nan, grad_fn=<AddBackward0>)\n",
            "Skipping NaN loss\n",
            "iteration 1\n",
            "loss tensor(nan, grad_fn=<AddBackward0>)\n",
            "Skipping NaN loss\n",
            "iteration 1\n",
            "loss tensor(5.2307, grad_fn=<AddBackward0>)\n",
            "iteration 1\n",
            "loss tensor(nan, grad_fn=<AddBackward0>)\n",
            "Skipping NaN loss\n",
            "iteration 1\n",
            "loss tensor(3.3031, grad_fn=<AddBackward0>)\n",
            "iteration 1\n",
            "loss tensor(nan, grad_fn=<AddBackward0>)\n",
            "Skipping NaN loss\n",
            "iteration 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2/2 [08:16<00:00, 248.13s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss tensor(nan, grad_fn=<AddBackward0>)\n",
            "Skipping NaN loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss_list"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2xcgzcKmuSUN",
        "outputId": "52253d36-af6e-4443-a5cd-e8ef92815dc3"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[12142.567273378372, 1864.0959092974663]"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(detector.state_dict(), 'detector.pt')"
      ],
      "metadata": {
        "id": "P_AWJD8ExUtl"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def training_loop(model, learning_rate, train_dataloader, val_dataset, n_epochs):\n",
        "    \n",
        "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "    loss_fn = nn.CrossEntropyLoss(weight=None, reduction='mean')\n",
        "    \n",
        "    model.train()\n",
        "    train_loss_list = []\n",
        "    val_loss_list = []\n",
        "    val_acc_list = []\n",
        "    \n",
        "    for i in tqdm(range(n_epochs)):\n",
        "        # Train\n",
        "        train_total_loss = 0\n",
        "        for img_batch, gt_bboxes_batch, gt_classes_batch in tqdm(train_dataloader):\n",
        "            # Forward pass\n",
        "            train_loss = model(img_batch, gt_bboxes_batch, gt_classes_batch)\n",
        "            \n",
        "            if torch.isnan(train_loss):\n",
        "                print(\"Skipping NaN loss\")\n",
        "                continue\n",
        "            \n",
        "            # Backpropagation\n",
        "            optimizer.zero_grad()\n",
        "            train_loss.backward()\n",
        "            optimizer.step()\n",
        "            \n",
        "            train_total_loss += train_loss.item()\n",
        "        \n",
        "        train_loss_list.append(train_total_loss)\n",
        "        \n",
        "        # Validation\n",
        "        model.eval()\n",
        "        val_total_loss = 0\n",
        "        val_total_correct = 0\n",
        "        val_total_samples = 0\n",
        "        val_dataloader = DataLoader(val_dataset, batch_size = 64)\n",
        "        with torch.no_grad():\n",
        "            for img_batch, gt_bboxes_batch, gt_classes_batch in val_dataloader:\n",
        "                # Forward pass\n",
        "                val_loss = model(img_batch, gt_bboxes_batch, gt_classes_batch)\n",
        "                val_total_loss += val_loss.item()\n",
        "               \n",
        "        val_loss_list.append(val_total_loss)\n",
        "        val_acc = get_accuracy(model,val_dataset)\n",
        "        val_acc_list.append(val_acc)\n",
        "        \n",
        "        model.train()\n",
        "        \n",
        "    return train_loss_list, val_loss_list, val_acc_list\n"
      ],
      "metadata": {
        "id": "1rPfm6D6xjOM"
      },
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val_csv_path = \"/content/APS360_Traffic_Sign_Recognition/val.csv\""
      ],
      "metadata": {
        "id": "AK0ZNVYqyKvD"
      },
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val_dataset = ObjectDetectionDataset(val_csv_path, (img_height, img_width), name2idx)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gJ8NWDa_yRDU",
        "outputId": "cc1e3a5d-90ac-4b29-a207-f25aba4df81e"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 729/729 [00:04<00:00, 149.64it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "val_dataloader = DataLoader(val_dataset, batch_size = 32)"
      ],
      "metadata": {
        "id": "jD9_kd9YycO8"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "detector = TwoStageDetector(img_size, out_size, out_c, n_classes, roi_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3BVozQrryi-q",
        "outputId": "49df148e-2406-400b-bb94-2ba5274e05fc"
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lr = 0.05\n",
        "n_epochs = 2\n",
        "train_loss_list, val_loss_list, val_acc_list = training_loop(detector, lr, od_dataloader, val_dataset, n_epochs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "OQr6sXa2yt4z",
        "outputId": "5ecc5fca-031b-4fa0-f9d7-db9f6240da3a"
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/2 [00:00<?, ?it/s]\n",
            "  0%|          | 0/102 [00:00<?, ?it/s]\u001b[A\n",
            "  1%|          | 1/102 [00:02<03:57,  2.35s/it]\u001b[A\n",
            "  2%|▏         | 2/102 [00:04<03:47,  2.28s/it]\u001b[A\n",
            "  3%|▎         | 3/102 [00:07<04:23,  2.66s/it]\u001b[A\n",
            "  4%|▍         | 4/102 [00:10<04:07,  2.52s/it]\u001b[A\n",
            "  5%|▍         | 5/102 [00:12<03:53,  2.40s/it]\u001b[A\n",
            "  6%|▌         | 6/102 [00:14<03:44,  2.34s/it]\u001b[A\n",
            "  7%|▋         | 7/102 [00:16<03:38,  2.30s/it]\u001b[A\n",
            "  8%|▊         | 8/102 [00:19<03:48,  2.43s/it]\u001b[A\n",
            "  9%|▉         | 9/102 [00:21<03:51,  2.49s/it]\u001b[A\n",
            " 10%|▉         | 10/102 [00:24<03:40,  2.40s/it]\u001b[A\n",
            " 11%|█         | 11/102 [00:26<03:33,  2.35s/it]\u001b[A\n",
            " 12%|█▏        | 12/102 [00:28<03:27,  2.31s/it]\u001b[A\n",
            " 13%|█▎        | 13/102 [00:30<03:25,  2.31s/it]\u001b[A\n",
            " 14%|█▎        | 14/102 [00:34<03:43,  2.54s/it]\u001b[A\n",
            " 15%|█▍        | 15/102 [00:36<03:30,  2.42s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Skipping NaN loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            " 16%|█▌        | 16/102 [00:38<03:23,  2.36s/it]\u001b[A\n",
            " 17%|█▋        | 17/102 [00:40<03:14,  2.29s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Skipping NaN loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            " 18%|█▊        | 18/102 [00:42<03:10,  2.27s/it]\u001b[A\n",
            " 19%|█▊        | 19/102 [00:45<03:26,  2.48s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Skipping NaN loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            " 20%|█▉        | 20/102 [00:48<03:20,  2.45s/it]\u001b[A\n",
            " 21%|██        | 21/102 [00:50<03:12,  2.38s/it]\u001b[A\n",
            " 22%|██▏       | 22/102 [00:52<03:06,  2.34s/it]\u001b[A\n",
            " 23%|██▎       | 23/102 [00:54<03:00,  2.28s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Skipping NaN loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            " 24%|██▎       | 24/102 [00:57<03:07,  2.40s/it]\u001b[A\n",
            " 25%|██▍       | 25/102 [01:00<03:11,  2.49s/it]\u001b[A\n",
            " 25%|██▌       | 26/102 [01:02<03:03,  2.41s/it]\u001b[A\n",
            " 26%|██▋       | 27/102 [01:04<02:56,  2.35s/it]\u001b[A\n",
            " 27%|██▋       | 28/102 [01:06<02:49,  2.29s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Skipping NaN loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            " 28%|██▊       | 29/102 [01:08<02:45,  2.27s/it]\u001b[A\n",
            " 29%|██▉       | 30/102 [01:11<03:02,  2.53s/it]\u001b[A\n",
            " 30%|███       | 31/102 [01:14<02:52,  2.43s/it]\u001b[A\n",
            " 31%|███▏      | 32/102 [01:16<02:46,  2.38s/it]\u001b[A\n",
            " 32%|███▏      | 33/102 [01:18<02:40,  2.33s/it]\u001b[A\n",
            " 33%|███▎      | 34/102 [01:20<02:35,  2.28s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Skipping NaN loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            " 34%|███▍      | 35/102 [01:24<02:53,  2.59s/it]\u001b[A\n",
            " 35%|███▌      | 36/102 [01:26<02:44,  2.49s/it]\u001b[A\n",
            " 36%|███▋      | 37/102 [01:28<02:36,  2.41s/it]\u001b[A\n",
            " 37%|███▋      | 38/102 [01:30<02:30,  2.36s/it]\u001b[A\n",
            " 38%|███▊      | 39/102 [01:33<02:24,  2.30s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Skipping NaN loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            " 39%|███▉      | 40/102 [01:35<02:31,  2.45s/it]\u001b[A\n",
            " 40%|████      | 41/102 [01:38<02:32,  2.50s/it]\u001b[A\n",
            " 41%|████      | 42/102 [01:40<02:25,  2.42s/it]\u001b[A\n",
            " 42%|████▏     | 43/102 [01:42<02:17,  2.34s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Skipping NaN loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            " 43%|████▎     | 44/102 [01:44<02:12,  2.28s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Skipping NaN loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            " 44%|████▍     | 45/102 [01:47<02:10,  2.30s/it]\u001b[A\n",
            " 45%|████▌     | 46/102 [01:50<02:20,  2.51s/it]\u001b[A\n",
            " 46%|████▌     | 47/102 [01:52<02:12,  2.40s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Skipping NaN loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            " 47%|████▋     | 48/102 [01:54<02:05,  2.33s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Skipping NaN loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            " 48%|████▊     | 49/102 [01:56<02:00,  2.27s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Skipping NaN loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            " 49%|████▉     | 50/102 [01:59<01:58,  2.27s/it]\u001b[A\n",
            " 50%|█████     | 51/102 [02:02<02:07,  2.51s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Skipping NaN loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            " 51%|█████     | 52/102 [02:04<02:01,  2.44s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Skipping NaN loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            " 52%|█████▏    | 53/102 [02:06<01:55,  2.37s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Skipping NaN loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            " 53%|█████▎    | 54/102 [02:08<01:50,  2.31s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Skipping NaN loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            " 54%|█████▍    | 55/102 [02:10<01:46,  2.26s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Skipping NaN loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            " 55%|█████▍    | 56/102 [02:13<01:46,  2.32s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Skipping NaN loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            " 56%|█████▌    | 57/102 [02:16<01:49,  2.44s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Skipping NaN loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            " 57%|█████▋    | 58/102 [02:18<01:43,  2.35s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Skipping NaN loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            " 58%|█████▊    | 59/102 [02:20<01:38,  2.30s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Skipping NaN loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            " 59%|█████▉    | 60/102 [02:22<01:35,  2.27s/it]\u001b[A\n",
            " 60%|█████▉    | 61/102 [02:24<01:32,  2.26s/it]\u001b[A\n",
            " 61%|██████    | 62/102 [02:28<01:41,  2.54s/it]\u001b[A\n",
            " 62%|██████▏   | 63/102 [02:30<01:35,  2.45s/it]\u001b[A\n",
            " 63%|██████▎   | 64/102 [02:32<01:30,  2.38s/it]\u001b[A\n",
            " 64%|██████▎   | 65/102 [02:34<01:26,  2.34s/it]\u001b[A\n",
            " 65%|██████▍   | 66/102 [02:36<01:22,  2.30s/it]\u001b[A\n",
            " 66%|██████▌   | 67/102 [02:39<01:28,  2.53s/it]\u001b[A\n",
            " 67%|██████▋   | 68/102 [02:42<01:24,  2.48s/it]\u001b[A\n",
            " 68%|██████▊   | 69/102 [02:44<01:19,  2.41s/it]\u001b[A\n",
            " 69%|██████▊   | 70/102 [02:46<01:15,  2.35s/it]\u001b[A\n",
            " 70%|██████▉   | 71/102 [02:49<01:18,  2.52s/it]\u001b[A\n",
            " 71%|███████   | 72/102 [02:52<01:20,  2.69s/it]\u001b[A\n",
            " 72%|███████▏  | 73/102 [02:55<01:15,  2.59s/it]\u001b[A\n",
            " 73%|███████▎  | 74/102 [02:57<01:09,  2.49s/it]\u001b[A\n",
            " 74%|███████▎  | 75/102 [02:59<01:05,  2.41s/it]\u001b[A\n",
            " 75%|███████▍  | 76/102 [03:01<01:01,  2.36s/it]\u001b[A\n",
            " 75%|███████▌  | 77/102 [03:04<01:01,  2.44s/it]\u001b[A\n",
            " 76%|███████▋  | 78/102 [03:07<01:00,  2.52s/it]\u001b[A\n",
            " 77%|███████▋  | 79/102 [03:09<00:56,  2.44s/it]\u001b[A\n",
            " 78%|███████▊  | 80/102 [03:11<00:52,  2.37s/it]\u001b[A\n",
            " 79%|███████▉  | 81/102 [03:13<00:48,  2.33s/it]\u001b[A\n",
            " 80%|████████  | 82/102 [03:16<00:46,  2.31s/it]\u001b[A\n",
            " 81%|████████▏ | 83/102 [03:19<00:48,  2.55s/it]\u001b[A\n",
            " 82%|████████▏ | 84/102 [03:21<00:44,  2.45s/it]\u001b[A\n",
            " 83%|████████▎ | 85/102 [03:23<00:40,  2.37s/it]\u001b[A\n",
            " 84%|████████▍ | 86/102 [03:25<00:37,  2.33s/it]\u001b[A\n",
            " 85%|████████▌ | 87/102 [03:28<00:34,  2.30s/it]\u001b[A\n",
            " 86%|████████▋ | 88/102 [03:31<00:36,  2.59s/it]\u001b[A\n",
            " 87%|████████▋ | 89/102 [03:33<00:32,  2.48s/it]\u001b[A\n",
            " 88%|████████▊ | 90/102 [03:35<00:28,  2.40s/it]\u001b[A\n",
            " 89%|████████▉ | 91/102 [03:38<00:25,  2.34s/it]\u001b[A\n",
            " 90%|█████████ | 92/102 [03:40<00:22,  2.30s/it]\u001b[A\n",
            " 91%|█████████ | 93/102 [03:42<00:21,  2.43s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Skipping NaN loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            " 92%|█████████▏| 94/102 [03:45<00:19,  2.47s/it]\u001b[A\n",
            " 93%|█████████▎| 95/102 [03:47<00:16,  2.39s/it]\u001b[A\n",
            " 94%|█████████▍| 96/102 [03:49<00:13,  2.32s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Skipping NaN loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            " 95%|█████████▌| 97/102 [03:52<00:11,  2.26s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Skipping NaN loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            " 96%|█████████▌| 98/102 [03:54<00:09,  2.27s/it]\u001b[A\n",
            " 97%|█████████▋| 99/102 [03:57<00:07,  2.49s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Skipping NaN loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            " 98%|█████████▊| 100/102 [03:59<00:04,  2.41s/it]\u001b[A\n",
            " 99%|█████████▉| 101/102 [04:01<00:02,  2.33s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Skipping NaN loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "100%|██████████| 102/102 [04:02<00:00,  2.38s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Skipping NaN loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\n",
            " 10%|█         | 1/10 [00:03<00:32,  3.66s/it]\u001b[A\n",
            " 20%|██        | 2/10 [00:08<00:34,  4.26s/it]\u001b[A\n",
            " 30%|███       | 3/10 [00:12<00:27,  3.99s/it]\u001b[A\n",
            " 40%|████      | 4/10 [00:15<00:23,  3.86s/it]\u001b[A\n",
            " 50%|█████     | 5/10 [00:20<00:20,  4.17s/it]\u001b[A\n",
            " 60%|██████    | 6/10 [00:24<00:16,  4.00s/it]\u001b[A\n",
            " 70%|███████   | 7/10 [00:27<00:11,  3.91s/it]\u001b[A\n",
            " 80%|████████  | 8/10 [00:32<00:08,  4.04s/it]\u001b[A\n",
            " 90%|█████████ | 9/10 [00:36<00:04,  4.04s/it]\u001b[A\n",
            "100%|██████████| 10/10 [00:39<00:00,  3.95s/it]\n",
            " 50%|█████     | 1/2 [05:19<05:19, 319.50s/it]\n",
            "  0%|          | 0/102 [00:00<?, ?it/s]\u001b[A\n",
            "  1%|          | 1/102 [00:02<03:46,  2.24s/it]\u001b[A\n",
            "  2%|▏         | 2/102 [00:05<04:16,  2.57s/it]\u001b[A\n",
            "  3%|▎         | 3/102 [00:07<04:13,  2.56s/it]\u001b[A\n",
            "  4%|▍         | 4/102 [00:09<03:57,  2.42s/it]\u001b[A\n",
            "  5%|▍         | 5/102 [00:12<03:47,  2.34s/it]\u001b[A\n",
            "  6%|▌         | 6/102 [00:14<03:41,  2.31s/it]\u001b[A\n",
            "  7%|▋         | 7/102 [00:16<03:40,  2.32s/it]\u001b[A\n",
            "  8%|▊         | 8/102 [00:19<03:59,  2.55s/it]\u001b[A\n",
            "  9%|▉         | 9/102 [00:21<03:47,  2.45s/it]\u001b[A\n",
            " 10%|▉         | 10/102 [00:24<03:39,  2.39s/it]\u001b[A\n",
            " 11%|█         | 11/102 [00:26<03:32,  2.34s/it]\u001b[A\n",
            " 12%|█▏        | 12/102 [00:28<03:26,  2.30s/it]\u001b[A\n",
            " 13%|█▎        | 13/102 [00:31<03:48,  2.57s/it]\u001b[A\n",
            " 14%|█▎        | 14/102 [00:33<03:37,  2.47s/it]\u001b[A\n",
            " 15%|█▍        | 15/102 [00:36<03:26,  2.37s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Skipping NaN loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            " 16%|█▌        | 16/102 [00:38<03:20,  2.34s/it]\u001b[A\n",
            " 17%|█▋        | 17/102 [00:40<03:13,  2.27s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Skipping NaN loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            " 18%|█▊        | 18/102 [00:43<03:28,  2.48s/it]\u001b[A\n",
            " 19%|█▊        | 19/102 [00:45<03:23,  2.46s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Skipping NaN loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            " 20%|█▉        | 20/102 [00:48<03:16,  2.39s/it]\u001b[A\n",
            " 21%|██        | 21/102 [00:50<03:09,  2.34s/it]\u001b[A\n",
            " 22%|██▏       | 22/102 [00:52<03:04,  2.30s/it]\u001b[A\n",
            " 23%|██▎       | 23/102 [00:54<03:01,  2.30s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Skipping NaN loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            " 24%|██▎       | 24/102 [00:57<03:15,  2.50s/it]\u001b[A\n",
            " 25%|██▍       | 25/102 [01:00<03:05,  2.41s/it]\u001b[A\n",
            " 25%|██▌       | 26/102 [01:02<02:59,  2.36s/it]\u001b[A\n",
            " 26%|██▋       | 27/102 [01:04<02:54,  2.33s/it]\u001b[A\n",
            " 27%|██▋       | 28/102 [01:06<02:48,  2.27s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Skipping NaN loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            " 28%|██▊       | 29/102 [01:09<03:06,  2.55s/it]\u001b[A\n",
            " 29%|██▉       | 30/102 [01:12<02:56,  2.45s/it]\u001b[A\n",
            " 30%|███       | 31/102 [01:14<02:49,  2.39s/it]\u001b[A\n",
            " 31%|███▏      | 32/102 [01:16<02:43,  2.34s/it]\u001b[A\n",
            " 32%|███▏      | 33/102 [01:18<02:38,  2.30s/it]\u001b[A\n",
            " 33%|███▎      | 34/102 [01:21<02:47,  2.47s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Skipping NaN loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            " 34%|███▍      | 35/102 [01:24<02:45,  2.47s/it]\u001b[A\n",
            " 35%|███▌      | 36/102 [01:26<02:37,  2.39s/it]\u001b[A\n",
            " 36%|███▋      | 37/102 [01:28<02:32,  2.34s/it]\u001b[A\n",
            " 37%|███▋      | 38/102 [01:30<02:27,  2.30s/it]\u001b[A\n",
            " 38%|███▊      | 39/102 [01:33<02:26,  2.32s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Skipping NaN loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            " 39%|███▉      | 40/102 [01:36<02:35,  2.51s/it]\u001b[A\n",
            " 40%|████      | 41/102 [01:38<02:28,  2.43s/it]\u001b[A\n",
            " 41%|████      | 42/102 [01:40<02:22,  2.37s/it]\u001b[A\n",
            " 42%|████▏     | 43/102 [01:42<02:15,  2.30s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Skipping NaN loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            " 43%|████▎     | 44/102 [01:44<02:11,  2.26s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Skipping NaN loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            " 44%|████▍     | 45/102 [01:48<02:25,  2.54s/it]\u001b[A\n",
            " 45%|████▌     | 46/102 [01:50<02:17,  2.45s/it]\u001b[A\n",
            " 46%|████▌     | 47/102 [01:52<02:09,  2.36s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Skipping NaN loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            " 47%|████▋     | 48/102 [01:54<02:05,  2.32s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Skipping NaN loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            " 48%|████▊     | 49/102 [01:56<02:00,  2.27s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Skipping NaN loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            " 49%|████▉     | 50/102 [01:59<02:07,  2.46s/it]\u001b[A\n",
            " 50%|█████     | 51/102 [02:02<02:05,  2.45s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Skipping NaN loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            " 51%|█████     | 52/102 [02:04<01:58,  2.36s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Skipping NaN loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            " 52%|█████▏    | 53/102 [02:06<01:52,  2.30s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Skipping NaN loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            " 53%|█████▎    | 54/102 [02:08<01:48,  2.26s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Skipping NaN loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            " 54%|█████▍    | 55/102 [02:10<01:46,  2.26s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Skipping NaN loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            " 55%|█████▍    | 56/102 [02:13<01:54,  2.49s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Skipping NaN loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            " 56%|█████▌    | 57/102 [02:16<01:47,  2.39s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Skipping NaN loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            " 57%|█████▋    | 58/102 [02:18<01:42,  2.32s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Skipping NaN loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            " 58%|█████▊    | 59/102 [02:20<01:38,  2.28s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Skipping NaN loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            " 59%|█████▉    | 60/102 [02:22<01:34,  2.26s/it]\u001b[A\n",
            " 60%|█████▉    | 61/102 [02:25<01:42,  2.50s/it]\u001b[A\n",
            " 61%|██████    | 62/102 [02:27<01:38,  2.45s/it]\u001b[A\n",
            " 62%|██████▏   | 63/102 [02:30<01:32,  2.38s/it]\u001b[A\n",
            " 63%|██████▎   | 64/102 [02:32<01:28,  2.33s/it]\u001b[A\n",
            " 64%|██████▎   | 65/102 [02:34<01:25,  2.30s/it]\u001b[A\n",
            " 65%|██████▍   | 66/102 [02:37<01:26,  2.41s/it]\u001b[A\n",
            " 66%|██████▌   | 67/102 [02:40<01:27,  2.50s/it]\u001b[A\n",
            " 67%|██████▋   | 68/102 [02:42<01:22,  2.42s/it]\u001b[A\n",
            " 68%|██████▊   | 69/102 [02:44<01:18,  2.37s/it]\u001b[A\n",
            " 69%|██████▊   | 70/102 [02:46<01:14,  2.32s/it]\u001b[A\n",
            " 70%|██████▉   | 71/102 [02:49<01:12,  2.33s/it]\u001b[A\n",
            " 71%|███████   | 72/102 [02:52<01:17,  2.57s/it]\u001b[A\n",
            " 72%|███████▏  | 73/102 [02:54<01:11,  2.48s/it]\u001b[A\n",
            " 73%|███████▎  | 74/102 [02:56<01:07,  2.42s/it]\u001b[A\n",
            " 74%|███████▎  | 75/102 [02:58<01:03,  2.36s/it]\u001b[A\n",
            " 75%|███████▍  | 76/102 [03:01<01:02,  2.39s/it]\u001b[A\n",
            " 75%|███████▌  | 77/102 [03:04<01:05,  2.63s/it]\u001b[A\n",
            " 76%|███████▋  | 78/102 [03:06<01:00,  2.51s/it]\u001b[A\n",
            " 77%|███████▋  | 79/102 [03:09<00:55,  2.43s/it]\u001b[A\n",
            " 78%|███████▊  | 80/102 [03:11<00:52,  2.37s/it]\u001b[A\n",
            " 79%|███████▉  | 81/102 [03:13<00:48,  2.33s/it]\u001b[A\n",
            " 80%|████████  | 82/102 [03:16<00:50,  2.54s/it]\u001b[A\n",
            " 81%|████████▏ | 83/102 [03:19<00:47,  2.50s/it]\u001b[A\n",
            " 82%|████████▏ | 84/102 [03:21<00:43,  2.42s/it]\u001b[A\n",
            " 83%|████████▎ | 85/102 [03:23<00:40,  2.36s/it]\u001b[A\n",
            " 84%|████████▍ | 86/102 [03:25<00:37,  2.32s/it]\u001b[A\n",
            " 85%|████████▌ | 87/102 [03:28<00:36,  2.40s/it]\u001b[A\n",
            " 86%|████████▋ | 88/102 [03:31<00:35,  2.51s/it]\u001b[A\n",
            " 87%|████████▋ | 89/102 [03:33<00:31,  2.42s/it]\u001b[A\n",
            " 88%|████████▊ | 90/102 [03:35<00:28,  2.36s/it]\u001b[A\n",
            " 89%|████████▉ | 91/102 [03:37<00:25,  2.32s/it]\u001b[A\n",
            " 90%|█████████ | 92/102 [03:39<00:22,  2.29s/it]\u001b[A\n",
            " 91%|█████████ | 93/102 [03:43<00:22,  2.54s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Skipping NaN loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            " 92%|█████████▏| 94/102 [03:45<00:19,  2.46s/it]\u001b[A\n",
            " 93%|█████████▎| 95/102 [03:47<00:16,  2.40s/it]\u001b[A\n",
            " 94%|█████████▍| 96/102 [03:49<00:14,  2.34s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Skipping NaN loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            " 95%|█████████▌| 97/102 [03:51<00:11,  2.30s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Skipping NaN loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            " 96%|█████████▌| 98/102 [03:55<00:10,  2.56s/it]\u001b[A\n",
            " 97%|█████████▋| 99/102 [03:57<00:07,  2.46s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Skipping NaN loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            " 98%|█████████▊| 100/102 [03:59<00:04,  2.39s/it]\u001b[A\n",
            " 99%|█████████▉| 101/102 [04:01<00:02,  2.31s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Skipping NaN loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "100%|██████████| 102/102 [04:02<00:00,  2.38s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Skipping NaN loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "  0%|          | 0/10 [00:03<?, ?it/s]\n",
            " 50%|█████     | 1/2 [10:03<10:03, 603.44s/it]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-90-80a3191094f0>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mlr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.05\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mn_epochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtrain_loss_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loss_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_acc_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtraining_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdetector\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mod_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-87-554c8cfc82b8>\u001b[0m in \u001b[0;36mtraining_loop\u001b[0;34m(model, learning_rate, train_dataloader, val_dataset, n_epochs)\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0mval_loss_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_total_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m         \u001b[0mval_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_accuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mval_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0mval_acc_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_acc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-83-ecf4106eb1cc>\u001b[0m in \u001b[0;36mget_accuracy\u001b[0;34m(model, data)\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgt_classes_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m                 \u001b[0my_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgt_classes_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m                 \u001b[0midx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconf_scores_final\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m                 \u001b[0mcurrent_class_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclasses_final\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m                 \u001b[0mcurrent_class\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcurrent_class_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: argmax(): Expected reduction dim to be specified for input.numel() == 0."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Pp-YhDAgy5We"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}